---
title: "Semaine 1"
format: 
  html:
    toc: true
    toc_float: 
      collapsed: false
      smooth_scroll: true
editor: visual
date: "2024-02-25"
image: "exercice.png"
categories: [TD]
author: "Isabel"
---

# TD 1

\
Dans la section TD, vous trouverez les solutions aux exercices des semaines 1, 2 et 3, ainsi que les réponses aux questions posées dans l'exercice 4 et pendant l'élaboration du projet. Pour faciliter la navigation dans le code et les réponses, vous pouvez utiliser soit la barre de recherche, soit la table des matières interactive située sur votre droite.

Voici quelques précisions avant de commencer :

-   Il est important de noter que toutes les librairies nécessaires à la réalisation de ces exercices sont téléchargées dans la première partie. (l'installation de certains packages peut être requise avant l'utilisation de la librairie)

-   L'encodage des caractères utilisé est UTF-8

-   La licence MIT a été choisi pour ce projet

-   La création d'un projet pour chaque ensemble d'exercices (par semaine) et de scripts a été réalisée afin de respecter les consignes et conseils. Cependant, ici, vous trouverez l'ensemble de toutes les semaines réunies

#### Librairies

```{r}
#| echo: true
#| eval: true
#| warning: false

# TD 1
library(geosphere)
library(tidygeocoder)
library(leaflet) 

```

```{r}
# penser à vérifer le chemin de travail et à le corriger si necessaire 
getwd()
```

```{r}
#| echo: false
setwd("/Users/Isabel/Desktop/Cours/R avancé/my_blog/posts/Excercices-TD")
```

# Exercices

Pour cet exercice, nous allons télécharger un jeu de données issu de <https://data.gouv.fr> sur les infrastructures olympiques des JO 2024 à Paris.

L’objectif de cet exercice est d’utiliser uniquement des fonctions de R base. - pas de librairie tierce sauf mention contraire.

## 2. Téléchargement jeu de données depuis le site

```{r}

url <- "https://www.data.gouv.fr/fr/datasets/r/3f8ea372-3847-495d-9b93-c4a76d553166"
data_ex <- read.csv(url, sep = ";")

```

```{r}
names(data_ex)
dim(data_ex)
str(data_ex)
```

Le nombre de lignes est de 31 pour 4 colonnes nomées : geo_point, nom, sites_olympiques_paralympiques, sports

## 3 et 4 Combien y a t’il de sites olympiques et paralympiques ?

```{r}
head(data_ex)
 
table(data_ex$sites_olympiques_paralympiques )


sites_olympiques <- 0
sites_paralympique <- 0

for (site in data_ex$sites_olympiques_paralympiques) {
  if( grepl("Site olympique", site)) {
    sites_olympiques <- sites_olympiques + 1
  }
  if(grepl("Site paralympique", site)){
    sites_paralympique <- sites_paralympique + 1
  }
}

print(paste("Il y a au total", sites_olympiques, "sites olympiques et", sites_paralympique, "sites paralympiques"))

```

## 5. Quels sont les sites qui accueillent plusieurs disciplines sportives ?

```{r}

sites_multi_sport <- data_ex[sapply(strsplit(data_ex$sports, ","), length) >1, ]
print("Les sites accueillant plusieurs disciplines sportives sont :")
print(sites_multi_sport$nom)

```

## 6. Quels sont les disciplines para-olympiques accueillies dans ces sites franciliens ?

(franciliens = De l'Île-de-France)

```{r}
data_paralympique <- data_ex[grepl("Site paralympique", data_ex$sites_olympiques_paralympiques), ]

disciplines_paralympiques <- unique(unlist(strsplit(data_paralympique$sports, ",")))

print(paste("Les disciplines para-olympiques accueillies sont:", paste(disciplines_paralympiques, collapse = ", ")))


```

**Concernant le code :**

La fonction **strsplit** est utilisée pour diviser des chaînes de caractères en sous-composants en fonction d'un séparateur spécifié.

**grepl** Est utile pour filtrer des données ou vérifier la présence de certaines sous-chaînes.

**unlist** Transforme la liste en un vecteur unique, concaténant tous les éléments des différentes entrées en un seul vecteur long.

**unique** Extrait les éléments uniques de ce vecteur, supprimant les répétitions.

## 7. Quel(s) site(s) accueille(nt) le plus de disciplines différentes ?

```{r}

sapply(strsplit(data_ex$sports, ","), function(x) length(unique(x)) )

nombre_de_disciplines <- data.frame(site = data_ex$nom, 
                         nombre_disciplines = sapply(strsplit(data_ex$sports, ","), function(x) length(unique(x))))

sites_nombre_disciplines <- nombre_de_disciplines[order                                            (-nombre_de_disciplines$nombre_disciplines),]

sites_4_disciplines <- sites_nombre_disciplines[sites_nombre_disciplines$nombre_disciplines>3,]

print(paste("Les sites accueillant les plus de disciplines (4) sont :", paste(sites_4_disciplines$site, collapse = ",")))


```

## 8. Quel discipline aura lieu sur le plus grand nombre de sites ? Quels sont ces sites ?

Pour répondre à la question, nous devons extraire les disciplines, les associer à chaque site et ensuite compter le nombre de sites par discipline:

```{r}
sites_et_disciplines <- data.frame(
  site = rep(data_ex$nom, sapply(data_ex$sports, function(x) length(strsplit(x, ",")[[1]]))),
  discipline = unlist(strsplit(data_ex$sports, ","))
)

nombre_sites_par_discipline <- aggregate(site ~ discipline, sites_et_disciplines, FUN = function(x) length(unique(x)))

```

Avec cet information, nous pouvons identifier la discipline qui est presente dans le plus grand nombre de sites :

```{r}
discipline_max_sites <- nombre_sites_par_discipline[which.max(nombre_sites_par_discipline$site), ]
discipline_max_sites
```

Et pour finir, nous pouvons voir les sites pour cette discipline :

```{r}
subset(sites_et_disciplines, discipline == discipline_max_sites$discipline)

```

## 9. A vol d’oiseau, quels sont les sites les deux sites les plus proches ?

Nous allons utiliser les coordonnées geographiques presentes dans la colonne geo_point et la fonction distHaversine, qui est une fonction du package geosphere pour calculer des distances sur une sphère entre deux points géolocalisés.

(Selon la documentation du package **`geosphere`**, la fonction **`distHaversine`** retournera les résultats en mètres.)

```{r}
head(data_ex$geo_point)
```

Comme nous pouvons le constater, la variable geo_point regroupe les coordonnées de latitude et de longitude. Par conséquent, nous allons les séparer en deux colonnes distinctes et les convertir en valeurs numériques:

```{r}
coords <- strsplit(as.character(data_ex$geo_point), ", ")
data_ex$latitude <- as.numeric(sapply(coords, `[`, 1))
data_ex$longitude <- as.numeric(sapply(coords, `[`, 2))
```

Maintenant nous pouvons calculer la matrice de distance entre tous les sites

```{r}

dist_matrix <- distm(data_ex[, c("longitude", "latitude")], fun = distHaversine)

# Remplacement de la diagonale par NA pour ignorer la distance de chaque site à lui-même
diag(dist_matrix) <- NA
```

Pour identifier les deux sites ayant la distance la plus courte entre eux. Nous allons :

```{r}

# Trouver la distance la plus courte à l'aide de min
min_dist <- min(dist_matrix, na.rm = TRUE)

# Identifier les sites les plus proches, on compare chaque élément de la matrice de distances 
sites_indices <- which(dist_matrix == min_dist, arr.ind = TRUE)

site1 <- data_ex$nom[sites_indices[1, 1]]  
site2 <- data_ex$nom[sites_indices[1, 2]]  

cat("Les deux sites les plus proches à vol d'oiseau sont :", site1, "et", site2,  "avec une distance de", round(min_dist), "mètres.\n")
```

## 10. Quels sont les deux sites les plus éloignés ?

Cette fois-ci, nous allons déterminer la distance maximale en utilisant la fonction max.

```{r}
max_dist <- max(dist_matrix, na.rm = TRUE)

```

Et maintenant, comme nous l'avons fait précédemment, nous pouvons identifier les indices correspondant à la distance maximale afin de déterminer les deux sites concernés.

```{r}
sites_indices_max <- which(dist_matrix == max_dist, arr.ind = TRUE)
site1_max <- data_ex$nom[sites_indices_max[1, 1]]  
site2_max <- data_ex$nom[sites_indices_max[1, 2]] 
cat("Les deux sites les plus éloignés à vol d'oiseau sont :", site1_max, "et", site2_max,  "avec une distance de", round(max_dist), "mètres.\n")

```

## 11. Où se situe le barycentre de l’ensemble des sites olympiques

Nous allons calculer les moyennes des latitudes et des longitudes pour trouver le barycentre.

```{r}
barycentre_lat <- mean(data_ex$latitude)
barycentre_lon <- mean(data_ex$longitude)
cat("L'appartement situé au barycentre de l'ensemble des sites olympiques se trouve à la latitude :", barycentre_lat, "et à la longitude :", barycentre_lon, "\n")

```

Maintenant, grâce à la fonction reverse_geocode, nous pourrons identifier l'adresse. Il est important de noter que reverse_geocode nécessite un argument de type .tbl (par exemple, un dataframe) pour fonctionner correctement. Nous enregistrerons donc les coordonnées dans un dataframe:

```{r}
#| warning: false

barycentre_df <- data.frame(
  lat = barycentre_lat,
  long = barycentre_lon
)

barycentre_adresse <- reverse_geocode(
  .tbl = barycentre_df, 
  lat = lat, 
  long = long,
  method = "osm" # Utilise OpenStreetMap pour le géocodage inverse
)

print(barycentre_adresse)

```

::: callout-tip
## Bonus - carte

Avec la question 11, nous concluons les exercices de la semaine 1. Avant de passer aux exercices de la semaine 2, nous pouvons créer un graphique en utilisant le dataframe barycentre_adresse et la fonction leaflet pour afficher sur une carte l'adresse que nous avons obtenue
:::

```{r}
leaflet(data = barycentre_adresse) |>
  addTiles() |>
  addMarkers(~long, ~lat, popup = ~address)

```
